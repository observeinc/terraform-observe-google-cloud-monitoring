locals {
  freshness = merge({}, var.freshness_overrides)

  enable_metrics  = lookup(var.feature_flags, "metrics", true)
  enable_monitors = lookup(var.feature_flags, "monitors", true)
  enable_both     = local.enable_monitors && local.enable_metrics

  /*

  workspace = local.datasets.REPLACE_WITH_DATASET_NAME.workspace
  name        = local.datasets.REPLACE_WITH_DATASET_NAME.name
  freshness   = local.datasets.REPLACE_WITH_DATASET_NAME.freshness
  description = local.datasets.REPLACE_WITH_DATASET_NAME.description

*/

  datasets = {
    cloud_sql_instance = {
      workspace   = local.workspace
      name        = format(var.name_format, "Instance")
      freshness   = lookup(local.freshness, "cloud_sql_instance", var.freshness_default_duration)
      description = "This dataset is used to create CloudSQL Resources"
    }

    cloud_sql_metrics_base = {
      workspace   = local.workspace
      name        = format(var.name_format, "Metrics Base")
      freshness   = lookup(local.freshness, "cloud_sql_metrics_base", var.freshness_default_duration)
      description = "This dataset contains all metric data generated by GCP for sql instances and is used to create other metric datasets"
    }

    cloud_sql_metrics = {
      workspace   = local.workspace
      name        = format(var.name_format, "Metrics")
      freshness   = lookup(local.freshness, "cloud_sql_metrics", var.freshness_default_duration)
      description = "This dataset contains metrics grouped by category and label"
    }

    cloud_sql_metrics_combo = {
      workspace   = local.workspace
      name        = format(var.name_format, "Metrics Combo")
      freshness   = lookup(local.freshness, "cloud_sql_metrics_combo", var.freshness_default_duration)
      description = "This dataset contains derived metrics"
    }

    cloud_sql_metrics_wide = {
      workspace   = local.workspace
      name        = format(var.name_format, "Metrics Wide")
      freshness   = lookup(local.freshness, "cloud_sql_metrics_wide", var.freshness_default_duration)
      description = "This dataset contains calculated metrics"
    }

    sql_logs = {
      workspace   = local.workspace
      name        = format(var.name_format, "Logs")
      freshness   = lookup(local.freshness, "sql_logs", var.freshness_default_duration)
      description = "This dataset contains raw logging data for sql instances"
    }

    activity_logs = {
      workspace   = local.workspace
      name        = format(var.name_format, "Logs Activity")
      freshness   = lookup(local.freshness, "activity_logs", var.freshness_default_duration)
      description = "This dataset contains logs of operations against sql instances"
    }

    cloud_sql_logs_error = {
      workspace   = local.workspace
      name        = format(var.name_format, "Logs Error")
      freshness   = lookup(local.freshness, "cloud_sql_logs_error", var.freshness_default_duration)
      description = "This dataset contains error logs for Postgres, MySQL and SQL Server database instances"
    }

    postgres_data_access_logs = {
      workspace   = local.workspace
      name        = format(var.name_format, "Logs Postgres Data Access")
      freshness   = lookup(local.freshness, "postgres_data_access_logs", var.freshness_default_duration)
      description = "This dataset contains logs for database commands issued against Postgres"
    }

    mysql_data_access_logs = {
      workspace   = local.workspace
      name        = format(var.name_format, "Logs MySql Data Access")
      freshness   = lookup(local.freshness, "mysql_data_access_logs", var.freshness_default_duration)
      description = "This dataset contains logs for database commands issued against MySql"
    }
  }
}

resource "observe_dataset" "cloud_sql_instance" {
  workspace   = local.datasets.cloud_sql_instance.workspace
  name        = local.datasets.cloud_sql_instance.name
  freshness   = local.datasets.cloud_sql_instance.freshness
  description = local.datasets.cloud_sql_instance.description
  icon_url    = "data/database-operations/database"

  inputs = {
    "events" = var.google.resource_asset_inventory_records.oid,
  }

  # https://cloud.google.com/sql/docs
  stage {
    pipeline = <<-EOF
      filter asset_type = "sqladmin.googleapis.com/Instance"
      make_col
        assetInventoryName:name,
        project_id: split_part(name, "/",5),
        name: split_part(name, "/",7),
        ipAddressObject:pivot_array(array(data.ipAddresses), "type", "ipAddress" )

      make_col
        database_id: strcat(project_id,":",name),
        createTime: parse_isotime(string(data.createTime))

    EOF
  }

  stage {
    pipeline = <<-EOF
      make_resource options(expiry:${var.max_expiry}),
        name,
        databaseVersion: string(data.databaseVersion),
        databaseInstalledVersion: string(data.databaseInstalledVersion),
        project_id,
        region:  string(data.region),
        backendType:string(data.backendType),
        backupConfiguration:data.settings.backupConfiguration,
        availabilityType:string(data.settings.availabilityType),
        dataDiskSizeGb:string(data.settings.dataDiskSizeGb),
        dataDiskType:string(data.settings.dataDiskType),
        databaseFlags:data.settings.databaseFlags,
        ipConfiguration:data.settings.ipConfiguration,
        tier:string(data.settings.tier),
        createTime,
        ipAddressPrimary: ipAddressObject.PRIMARY,
        ipAddresses:string(data.ipAddresses),
        gceZone:string(data.gceZone),
        ttl,
        deleted,
        assetInventoryName,
        primary_key(database_id),
        valid_for(ttl)

      add_key name

      set_label name

      //add_key project_id
      //add_key region
      add_key assetInventoryName
      
    EOF
  }
}

resource "observe_link" "project" {
  for_each = {
    "Projects" = {
      target = var.google.projects.oid
      fields = ["project_id"]
    }
  }

  workspace = var.workspace.oid
  source    = observe_dataset.cloud_sql_instance.oid
  target    = each.value.target
  fields    = each.value.fields
  label     = each.key
}
